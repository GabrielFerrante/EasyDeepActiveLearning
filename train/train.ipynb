{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8feb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from data_utils import get_svhn_loaders, SVHNCustomDataset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, _ in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Como labels são sequências (batch, max_len), \n",
    "        # a Loss depende de como você estruturou a saída do seu modelo\n",
    "        loss = criterion(outputs.view(-1, 11), labels.view(-1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # Lógica de predição simplificada\n",
    "            _, predicted = torch.max(outputs.data, 2)\n",
    "            total += labels.size(0) * labels.size(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_active_learning_cycle(model, train_dataset, labeled_indices, test_loader, device, config):\n",
    "    \"\"\"\n",
    "    Executa o treinamento para um conjunto específico de índices rotulados.\n",
    "    \"\"\"\n",
    "    # Criar DataLoader apenas com as amostras selecionadas (Labeled Set)\n",
    "    train_subset = Subset(train_dataset, labeled_indices)\n",
    "    train_loader = DataLoader(train_subset, batch_size=config['batch_size'], \n",
    "                              shuffle=True, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=10) # 10 é o pad_token\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        acc = validate(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: Loss {loss:.4f} | Test Acc: {acc:.2f}%\")\n",
    "    \n",
    "    return model, acc, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2da71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETROS\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = {\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 20,\n",
    "    'initial_budget': 1000, # Quantas imagens começam rotuladas\n",
    "    'cycle_budget': 500     # Quantas imagens adicionar por ciclo de AL\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar Dataset Completo (Pool)\n",
    "# Usamos o Dataset puro aqui para podermos manipular os índices via Subset\n",
    "train_ds = SVHNCustomDataset('train.csv', 'train_images/', transform=None) # Add transforms here\n",
    "test_ds = SVHNCustomDataset('test.csv', 'test_images/', transform=None)\n",
    "test_loader = DataLoader(test_ds, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização do Active Learning\n",
    "num_train = len(train_ds)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Índices das imagens que o modelo \"pode ver\"\n",
    "labeled_indices = indices[:config['initial_budget']]\n",
    "# Índices do pool não rotulado (Unlabeled pool)\n",
    "unlabeled_indices = indices[config['initial_budget']:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_al_checkpoint(model, optimizer, cycle, labeled_indices, acc, path=\"checkpoints\"):\n",
    "    \"\"\"\n",
    "    Salva o estado do modelo, otimizador e metadados do ciclo de AL.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    checkpoint = {\n",
    "        'cycle': cycle,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'labeled_indices': labeled_indices, # Essencial para saber o que foi usado no treino\n",
    "        'test_acc': acc\n",
    "    }\n",
    "    \n",
    "    filename = os.path.join(path, f\"model_cycle_{cycle}_acc_{acc:.2f}.pt\")\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint salvo: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ede9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Loop de Ciclos de Active Learning\n",
    "num_cycles = 5\n",
    "checkpoint_dir = \"al_checkpoints_svhn\"\n",
    "for cycle in range(num_cycles):\n",
    "    print(f\"\\n--- Iniciando Ciclo de AL {cycle} | Labeled Size: {len(labeled_indices)} ---\")\n",
    "    \n",
    "    # Inicializa/Reseta o modelo para cada ciclo (ou continua o treino)\n",
    "    model = YourModelArchitecture().to(device)\n",
    "    \n",
    "    # Treina o modelo com o que temos rotulado até agora\n",
    "    model, last_acc, opt = run_active_learning_cycle(model, train_ds, labeled_indices, test_loader, device, config)\n",
    "    \n",
    "    save_al_checkpoint(\n",
    "        model=model, \n",
    "        optimizer=opt, \n",
    "        cycle=cycle, \n",
    "        labeled_indices=labeled_indices, \n",
    "        acc=last_acc,\n",
    "        path=checkpoint_dir\n",
    "    )\n",
    "    \n",
    "    # --- ESPAÇO PARA SUA ESTRATÉGIA DE QUERY ---\n",
    "    # Aqui você chamaria sua função de seleção:\n",
    "    # new_indices = your_strategy.query(model, train_ds, unlabeled_indices, config['cycle_budget'])\n",
    "    \n",
    "    # Exemplo manual simplificado (Random Sampling):\n",
    "    new_indices = unlabeled_indices[:config['cycle_budget']]\n",
    "    \n",
    "    # Atualiza os conjuntos\n",
    "    labeled_indices = np.concatenate([labeled_indices, new_indices])\n",
    "    unlabeled_indices = unlabeled_indices[config['cycle_budget']:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
